ppo_config = {
    "max_steps_per_episode": 2048,
    "batch_size": 20,
    "lr": 0.001,
    "gamma": 0.99,
    "clip_ratio": 0.2,
    "train_iters": 4,
    "lam": 0.97,
    "ent_coef": 0.00,
    "value_coef": 0.5,
    "target_kl": 0.01,
}

